{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd75793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edda58ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py')\n",
    "\n",
    "root='../../dataset/'\n",
    "\n",
    "epoch = 'latest'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json'\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed=2021\n",
    "cfg.gpu_ids = [1]\n",
    "cfg.work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_trash'\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b086a8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b3eae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/faster_rcnn_r50_fpn_1x_trash/latest.pth\n"
     ]
    }
   ],
   "source": [
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f5c2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 4871/4871, 15.1 task/s, elapsed: 323s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05) # output 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d60f71a9-e50f-4824-90b4-b3f1636c159b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#output 시각화 (원래 없던 코드 내가 만든거)\n",
    "#output[i][j] > i번째 이미지에 j번째 클래스 박스들 모음 [x1(왼쪽상단x좌표),y1(왼쪽상단),x2(오른쪽하단),y2,클래스에 속할 확률]\n",
    "#현재는 전체 이미지에 박스를 씌운 이미지를 생성하는 코드\n",
    "import cv2\n",
    "class_names=[\"General trash\",\"Paper\",\"Paper pack\",\"Metal\",\"Glass\",\"Plastic\",\"Styrofoam\",\"Plastic bag\",\"Battery\",\"Clothing\"]\n",
    "for i,image_info in enumerate(output):\n",
    "    #image_id = image_info['id']\n",
    "    #test dataset일때랑 train data일때는 'test'를 'train'으로 변경\n",
    "    #숫자를 4자리 문자열로 바꿔줌 ( 3 >'0003')\n",
    "    stridx = str(i).zfill(4)\n",
    "    #test이미지가 있는 경로\n",
    "    image_path = os.path.join('../../dataset/test',stridx+'.jpg')\n",
    "    image = cv2.imread(image_path)\n",
    "    #boxes에는 박스 좌표를, class_ids는 클래스 ids를 저장\n",
    "    boxes=[]\n",
    "    class_ids=[]\n",
    "    for idx in range(10):\n",
    "        for tempidx in range(len(output[i][idx])):\n",
    "            boxes.append(output[i][idx][tempidx][:4])\n",
    "            class_ids.append(idx)\n",
    "           \n",
    "\n",
    "    # 클래스 id와 색상 매핑\n",
    "    class_colors = {\n",
    "    0: (0, 255, 0),   # 클래스0에 대한 색상 (초록색)\n",
    "    1: (0, 0, 255),   # 클래스1에 대한 색상 (빨간색)\n",
    "    2: (255, 0, 0),   # 클래스2에 대한 색상 (파란색)\n",
    "    3: (255, 255, 0), # 클래스3에 대한 색상 (노란색)\n",
    "    4: (255, 0, 255), # 클래스4에 대한 색상 (자홍색)\n",
    "    5: (0, 255, 255), # 클래스5에 대한 색상 (청록색)\n",
    "    6: (128, 128, 0), # 클래스6에 대한 색상 (올리브색)\n",
    "    7: (128, 0, 128), # 클래스7에 대한 색상 (보라색)\n",
    "    8: (0, 128, 128), # 클래스8에 대한 색상 (청록색)\n",
    "    9: (128, 128, 128)# 클래스9에 대한 색상 (회색)\n",
    "}\n",
    "\n",
    "    # 박스 시각화\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = class_ids[i]\n",
    "        color = class_colors[class_id]\n",
    "        class_name = class_names[class_id]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "        cv2.putText(image, class_name, (int(x1), int(y1)-5), font, font_scale, color, thickness)\n",
    "\n",
    "    # 결과 이미지 저장 (output 폴더안에 생성됨 inferenceoutput폴더 외에 다른 폴더에 만들고싶으면 ouput을 폴더명으로 바꺼주면댐)\n",
    "    output_path = os.path.join('inferenceoutput', 'infer_output_{}.jpg'.format(stridx))\n",
    "    cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5672a0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0.40757415 230.04446 671.318 297.78836 749.0...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0.38683057 709.2269 630.76385 891.5963 989.8...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 0.661221 871.38086 467.51266 1023.8762 628.5...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 0.19523789 6.5842514 36.088196 243.22034 757...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.5214785 171.76773 280.23077 866.6621 757.0...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  0 0.40757415 230.04446 671.318 297.78836 749.0...  test/0000.jpg\n",
       "1  0 0.38683057 709.2269 630.76385 891.5963 989.8...  test/0001.jpg\n",
       "2  0 0.661221 871.38086 467.51266 1023.8762 628.5...  test/0002.jpg\n",
       "3  0 0.19523789 6.5842514 36.088196 243.22034 757...  test/0003.jpg\n",
       "4  0 0.5214785 171.76773 280.23077 866.6621 757.0...  test/0004.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f23dc58-508a-4f9d-9ea2-a1dfe39e3a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: ./work_dirs/faster_rcnn_r50_fpn_1x_trash/latest.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 4883/4883, 28.9 task/s, elapsed: 169s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "#train 데이터 확인해보기\n",
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py')\n",
    "\n",
    "root='../../dataset/'\n",
    "\n",
    "epoch = 'latest'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'train.json'\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed=2021\n",
    "cfg.gpu_ids = [1]\n",
    "cfg.work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_trash'\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None\n",
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "\n",
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05) # output 계산\n",
    "#output 시각화 (원래 없던 코드 내가 만든거)\n",
    "#output[i][j] > i번째 이미지에 j번째 클래스 박스들 모음 [x1(왼쪽상단x좌표),y1(왼쪽상단),x2(오른쪽하단),y2,클래스에 속할 확률]\n",
    "#현재는 전체 이미지에 박스를 씌운 이미지를 생성하는 코드\n",
    "import cv2\n",
    "class_names=[\"General trash\",\"Paper\",\"Paper pack\",\"Metal\",\"Glass\",\"Plastic\",\"Styrofoam\",\"Plastic bag\",\"Battery\",\"Clothing\"]\n",
    "for i,image_info in enumerate(output):\n",
    "    #image_id = image_info['id']\n",
    "    #test dataset일때랑 train data일때는 'test'를 'train'으로 변경\n",
    "    #숫자를 4자리 문자열로 바꿔줌 ( 3 >'0003')\n",
    "    stridx = str(i).zfill(4)\n",
    "    #test이미지가 있는 경로\n",
    "    image_path = os.path.join('../../dataset/train',stridx+'.jpg')\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    boxes=[]\n",
    "    class_ids=[]\n",
    "    for idx in range(10):\n",
    "        for tempidx in range(len(output[i][idx])):\n",
    "            boxes.append(output[i][idx][tempidx][:4])\n",
    "            class_ids.append(idx)\n",
    "           \n",
    "\n",
    "    # 클래스 id와 색상 매핑\n",
    "    class_colors = {\n",
    "    0: (0, 255, 0),   # 클래스0에 대한 색상 (초록색)\n",
    "    1: (0, 0, 255),   # 클래스1에 대한 색상 (빨간색)\n",
    "    2: (255, 0, 0),   # 클래스2에 대한 색상 (파란색)\n",
    "    3: (255, 255, 0), # 클래스3에 대한 색상 (노란색)\n",
    "    4: (255, 0, 255), # 클래스4에 대한 색상 (자홍색)\n",
    "    5: (0, 255, 255), # 클래스5에 대한 색상 (청록색)\n",
    "    6: (128, 128, 0), # 클래스6에 대한 색상 (올리브색)\n",
    "    7: (128, 0, 128), # 클래스7에 대한 색상 (보라색)\n",
    "    8: (0, 128, 128), # 클래스8에 대한 색상 (청록색)\n",
    "    9: (128, 128, 128)# 클래스9에 대한 색상 (회색)\n",
    "}\n",
    "\n",
    "    # 박스 시각화\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = class_ids[i]\n",
    "        color = class_colors[class_id]\n",
    "        class_name = class_names[class_id]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "        cv2.putText(image, class_name, (int(x1), int(y1)-5), font, font_scale, color, thickness)\n",
    "\n",
    "    # 결과 이미지 저장 (output 폴더안에 생성됨 output폴더 외에 다른 폴더에 만들고싶으면 ouput을 폴더명으로 바꺼주면댐)\n",
    "    output_path = os.path.join('trainoutput', 'train_output_{}.jpg'.format(stridx))\n",
    "    cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7fcd0-d715-4612-a027-d3c8402b0ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
